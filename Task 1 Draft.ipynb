{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1114 out of 1,000,000 related reviews\n",
      "1124 out of 1,000,000 related reviews\n",
      "999 out of 1,000,000 related reviews\n",
      "1065 out of 1,000,000 related reviews\n",
      "848 out of 1,000,000 related reviews\n",
      "993 out of 1,000,000 related reviews\n",
      "1831 out of 1,000,000 related reviews\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "business_json_path = 'data/yelp_academic_dataset_business.json'\n",
    "df_b = pd.read_json(business_json_path, lines=True)\n",
    "\n",
    "# 1 = open, 0 = closed\n",
    "df_b = df_b[df_b['is_open']==1]\n",
    "\n",
    "drop_columns = ['hours','is_open','review_count']\n",
    "df_b = df_b.drop(drop_columns, axis=1)\n",
    "\n",
    "business_RV = df_b[df_b['categories'].str.contains(\n",
    "              'RV Repair|RV Dealers|RV Rental|RV Parks|Campgrounds',\n",
    "              case=False, na=False)]\n",
    "\n",
    "df_explode = df_b.assign(categories = df_b.categories\n",
    "                         .str.split(', ')).explode('categories')\n",
    "\n",
    "df_explode.categories.value_counts()\n",
    "\n",
    "df_explode[df_explode.categories.str.contains('RV',\n",
    "                      case=True,na=False)].categories.value_counts()\n",
    "\n",
    "review_json_path = 'data/yelp_academic_dataset_review.json'\n",
    "size = 1000000\n",
    "review = pd.read_json(review_json_path, lines=True,\n",
    "                      dtype={'review_id':str,'user_id':str,\n",
    "                             'business_id':str,'stars':int,\n",
    "                             'date':str,'text':str,'useful':int,\n",
    "                             'funny':int,'cool':int},\n",
    "                      chunksize=size)\n",
    "\n",
    "\n",
    "chunk_list = []\n",
    "for chunk_review in review:\n",
    "    # Drop columns that aren't needed\n",
    "    chunk_review = chunk_review.drop(['review_id','useful','funny','cool'], axis=1)\n",
    "    # Renaming column name to avoid conflict with business overall star rating\n",
    "    chunk_review = chunk_review.rename(columns={'stars': 'review_stars'})\n",
    "    # Inner merge with edited business file so only reviews related to the business remain\n",
    "    chunk_merged = pd.merge(business_RV, chunk_review, on='business_id', how='inner')\n",
    "    # Show feedback on progress\n",
    "    print(f\"{chunk_merged.shape[0]} out of {size:,} related reviews\")\n",
    "    chunk_list.append(chunk_merged)\n",
    "# After trimming down the review file, concatenate all relevant data back to one dataframe\n",
    "df = pd.concat(chunk_list, ignore_index=True, join='outer', axis=0)\n",
    "\n",
    "csv_name = \"yelp_reviews_RV_categories.csv\"\n",
    "df.to_csv(csv_name, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy pandas scikit-learn nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy pandas scikit-learn nltk\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('yelp_reviews_RV_categories.csv')\n",
    "texts = data['review_text']  # This should be the name of the column containing the text\n",
    "labels = data['attribute']   # This should be the name of the column with the labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Creating a pipeline that first creates bag of words (after removing stopwords), then applies TF-IDF\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words=stopwords.words('english'))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Train the classifier\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print out the classification report and accuracy\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "data = pd.read_csv('yelp_reviews_RV_categories.csv')\n",
    "texts = data['review_text']  # This should be the name of the column containing the text\n",
    "labels = data['attribute']   # This should be the name of the column with the labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pipeline that first creates bag of words (after removing stopwords), then applies TF-IDF\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words=stopwords.words('english'))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print out the classification report and accuracy\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
